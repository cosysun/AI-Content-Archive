#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AI å†…å®¹åˆ›ä½œå·¥ä½œæµ - è‡ªåŠ¨åŒ–è„šæœ¬
æ•´åˆhumanizerå»AIå‘³åŠŸèƒ½
ä½œè€…ï¼šAI Content Creator
æ—¥æœŸï¼š2026-02-19
ç‰ˆæœ¬ï¼š2.0 (é›†æˆhumanizer)
"""

import os
import re
from datetime import datetime
from pathlib import Path

# humanizerè§„åˆ™ï¼ˆåŸºäºSKILL.mdï¼‰
class HumanizerRules:
    """AIå†™ä½œæ¨¡å¼æ£€æµ‹å’Œä¿®å¤è§„åˆ™"""
    
    # éœ€è¦æ›¿æ¢çš„AIè¯æ±‡
    AI_VOCABULARY = {
        'æ­¤å¤–': 'å¦å¤–',
        'å¦å¤–': '',  # ç›´æ¥åˆ é™¤
        'å…³é”®æ˜¯': 'é‡è¦çš„æ˜¯',
        'è‡³å…³é‡è¦': 'é‡è¦',
        'æ·±å…¥æ¢è®¨': 'ç ”ç©¶',
        'æ·±å…¥äº†è§£': 'äº†è§£',
        'ä»¤äººå°è±¡æ·±åˆ»': 'å¾ˆå¥½',
        'å€¼å¾—æ³¨æ„çš„æ˜¯': '',
        'æ˜¾è‘—æå‡': 'æå‡',
        'æ˜¾è‘—æ”¹å–„': 'æ”¹å–„',
        'æå¤§åœ°': 'å¤§å¹…',
        'æŒç»­ä¸æ–­': 'æŒç»­',
        'æ—¥ç›Šå¢é•¿': 'å¢é•¿',
    }
    
    # promotionalè¯­è¨€æ¨¡å¼
    PROMOTIONAL_PATTERNS = [
        (r'éœ‡æƒŠ[äº†ï¼]', ''),
        (r'å…¨çƒé¦–ä¸ª', ''),
        (r'å¸Œæœ›ä¹‹å…‰', 'å¸Œæœ›'),
        (r'çªç ´æ€§çš„', ''),
        (r'é©å‘½æ€§çš„', ''),
        (r'é‡Œç¨‹ç¢‘å¼', ''),
        (r'åˆ’æ—¶ä»£', ''),
        (r'å‰æ‰€æœªæœ‰', ''),
        (r'å²æ— å‰ä¾‹', ''),
        (r'ä»¤äººç©ç›®', ''),
    ]
    
    # è¡¨æƒ…ç¬¦å·ï¼ˆéœ€è¦ç§»é™¤ï¼‰
    EMOJI_PATTERN = r'[ğŸ”¥ğŸ’¡âœ…âŒâš ï¸ğŸ“ŠğŸ¯ğŸš€ğŸ’°ğŸ¥ğŸ“šğŸ§¬ğŸ“„ğŸŒğŸ‘¨â€âš•ï¸ğŸ’¬â“ğŸğŸ“±ğŸ“ğŸ’¡ğŸ› ï¸âš¡ğŸ“ˆâ­ğŸ¬]+'
    
    # è¿‡åº¦å¼ºè°ƒæ¨¡å¼
    EMPHASIS_PATTERNS = [
        (r'ã€([^ã€‘]+)ã€‘', r'\1'),  # ç§»é™¤ã€ã€‘
        (r'ã€Š([^ã€‹]+)ã€‹', r'\1'),  # ä¿ç•™ä¹¦åä½†å»æ‰ä¹¦åå·
        (r'\*\*([^*]+)\*\*', r'\1'),  # ç§»é™¤ç²—ä½“**
    ]

def humanize_text(text):
    """å¯¹æ–‡æœ¬è¿›è¡Œå»AIå‘³å¤„ç†"""
    
    # 1. ç§»é™¤è¡¨æƒ…ç¬¦å·
    text = re.sub(HumanizerRules.EMOJI_PATTERN, '', text)
    
    # 2. æ›¿æ¢AIè¯æ±‡
    for ai_word, replacement in HumanizerRules.AI_VOCABULARY.items():
        if replacement:
            text = text.replace(ai_word, replacement)
        else:
            text = text.replace(ai_word + 'ï¼Œ', '')
            text = text.replace(ai_word + ',', '')
    
    # 3. ç§»é™¤promotionalè¯­è¨€
    for pattern, replacement in HumanizerRules.PROMOTIONAL_PATTERNS:
        text = re.sub(pattern, replacement, text)
    
    # 4. ç®€åŒ–è¿‡åº¦å¼ºè°ƒ
    for pattern, replacement in HumanizerRules.EMPHASIS_PATTERNS:
        text = re.sub(pattern, replacement, text)
    
    # 5. ç§»é™¤å¤šä½™çš„ç©ºè¡Œï¼ˆè¶…è¿‡2ä¸ªè¿ç»­æ¢è¡Œï¼‰
    text = re.sub(r'\n{3,}', '\n\n', text)
    
    # 6. ç§»é™¤è¡Œé¦–è¡Œå°¾ç©ºæ ¼
    lines = text.split('\n')
    lines = [line.strip() for line in lines]
    text = '\n'.join(lines)
    
    return text

def humanize_file(input_path, output_path):
    """å¤„ç†å•ä¸ªæ–‡ä»¶"""
    try:
        with open(input_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # åº”ç”¨humanizerè§„åˆ™
        humanized_content = humanize_text(content)
        
        # ä¿å­˜
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(humanized_content)
        
        return True
    except Exception as e:
        print(f"å¤„ç†æ–‡ä»¶å¤±è´¥: {e}")
        return False

def process_daily_content(date_str=None):
    """å¤„ç†æ¯æ—¥ç”Ÿæˆçš„å†…å®¹"""
    if date_str is None:
        date_str = datetime.now().strftime("%Y%m%d")
    
    base_dir = Path(__file__).parent
    output_dir = base_dir / "output"
    
    files_to_process = [
        (f"{date_str}_wechat_article.md", f"{date_str}_wechat_article_humanized.md"),
        (f"{date_str}_xiaohongshu_post.md", f"{date_str}_xiaohongshu_post_humanized.md"),
        (f"{date_str}_video_script.md", f"{date_str}_video_script_humanized.md"),
    ]
    
    processed_count = 0
    
    print(f"\n>>> å¼€å§‹å¤„ç† {date_str} çš„å†…å®¹...\n")
    
    for input_name, output_name in files_to_process:
        input_path = output_dir / input_name
        output_path = output_dir / output_name
        
        if not input_path.exists():
            print(f"[!] æ–‡ä»¶ä¸å­˜åœ¨: {input_name}")
            continue
        
        print(f"[>] å¤„ç†: {input_name}")
        if humanize_file(input_path, output_path):
            print(f"[OK] å®Œæˆ: {output_name}")
            processed_count += 1
        else:
            print(f"[FAIL] å¤±è´¥: {input_name}")
    
    print(f"\n>>> å¤„ç†å®Œæˆï¼æˆåŠŸå¤„ç† {processed_count}/{len(files_to_process)} ä¸ªæ–‡ä»¶")
    
    return processed_count

def show_usage():
    """æ˜¾ç¤ºä½¿ç”¨è¯´æ˜"""
    usage = """
============================================================
   AIå†…å®¹åˆ›ä½œå·¥ä½œæµ - Humanizeré›†æˆç‰ˆ v2.0
============================================================

[ä½¿ç”¨æ–¹æ³•]

1. å¤„ç†ä»Šå¤©çš„å†…å®¹:
   python humanizer_integration.py

2. å¤„ç†æŒ‡å®šæ—¥æœŸçš„å†…å®¹:
   python humanizer_integration.py 20260219

3. æµ‹è¯•å•ä¸ªæ–‡ä»¶:
   python humanizer_integration.py test input.md output.md

[åŠŸèƒ½è¯´æ˜]

- è‡ªåŠ¨ç§»é™¤è¡¨æƒ…ç¬¦å·
- æ›¿æ¢AIè¯æ±‡ ("æ­¤å¤–"ã€"å…³é”®æ˜¯"ç­‰)
- ç§»é™¤promotionalè¯­è¨€ ("éœ‡æƒŠ"ã€"å…¨çƒé¦–ä¸ª"ç­‰)
- ç®€åŒ–è¿‡åº¦å¼ºè°ƒ (**ç²—ä½“**ã€ã€ã€‘ç­‰)
- æ¸…ç†å¤šä½™ç©ºè¡Œå’Œç©ºæ ¼

[æ–‡ä»¶å‘½åè§„åˆ™]

åŸå§‹æ–‡ä»¶: YYYYMMDD_wechat_article.md
å¤„ç†å: YYYYMMDD_wechat_article_humanized.md

[é›†æˆåˆ°å®šæ—¶ä»»åŠ¡]

åœ¨å®šæ—¶ä»»åŠ¡ä¸­æ·»åŠ è¿™ä¸€æ­¥:
AIç”Ÿæˆå†…å®¹ -> humanizerå¤„ç† -> ä¿å­˜æ–‡ä»¶ -> å‘é€é€šçŸ¥

============================================================
"""
    print(usage)

def test_mode(input_path, output_path):
    """æµ‹è¯•æ¨¡å¼ï¼šå¤„ç†å•ä¸ªæ–‡ä»¶"""
    print(f"\n[TEST] æµ‹è¯•æ¨¡å¼\n")
    print(f"è¾“å…¥æ–‡ä»¶: {input_path}")
    print(f"è¾“å‡ºæ–‡ä»¶: {output_path}")
    
    if humanize_file(input_path, output_path):
        print(f"\n[OK] æµ‹è¯•æˆåŠŸï¼")
        print(f"è¯·æ£€æŸ¥è¾“å‡ºæ–‡ä»¶: {output_path}")
    else:
        print(f"\n[FAIL] æµ‹è¯•å¤±è´¥")

def main():
    """ä¸»å‡½æ•°"""
    import sys
    
    if len(sys.argv) == 1:
        # æ— å‚æ•°ï¼šå¤„ç†ä»Šå¤©çš„å†…å®¹
        process_daily_content()
        
    elif len(sys.argv) == 2:
        arg = sys.argv[1]
        
        if arg in ['help', '--help', '-h']:
            show_usage()
        elif arg == 'test':
            print("[ERROR] testæ¨¡å¼éœ€è¦æŒ‡å®šè¾“å…¥è¾“å‡ºæ–‡ä»¶")
            print("ç”¨æ³•: python humanizer_integration.py test input.md output.md")
        else:
            # å‡è®¾æ˜¯æ—¥æœŸ
            process_daily_content(arg)
    
    elif len(sys.argv) == 4 and sys.argv[1] == 'test':
        # testæ¨¡å¼
        input_path = sys.argv[2]
        output_path = sys.argv[3]
        test_mode(input_path, output_path)
    
    else:
        print("[ERROR] å‚æ•°é”™è¯¯")
        show_usage()

if __name__ == "__main__":
    main()
